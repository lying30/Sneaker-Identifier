{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Previous Code Version Sneaker Identifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was my original project code, but the tutorial that guided me through creating image classification was 6 years old, thus making this code outdated for this version of Python. In result, I used ChatGPT to help me transfer my code that would work for Python 3.5.3 to work for Python 3.10.6. This will explain the numerous pieces of code in identifier2.ipynb that are created using the assistance of ChatGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from random import shuffle\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "TEST_DIR = '/Users/Lucas_Ying/Desktop/ATCS/Final Project_SneakerIdentifier/Sneaker-Identifier/data/TestingData'\n",
    "TRAIN_DIR = '/Users/Lucas_Ying/Desktop/ATCS/Final Project_SneakerIdentifier/Sneaker-Identifier/data/TrainingData'\n",
    "\n",
    "IMG_SIZE = 120\n",
    "# learning rate\n",
    "LR = 1e-3\n",
    "\n",
    "MODEL_NAME = 'OFFWHITEvsYEEZY--{}-{}.model'.format(LR, '2conv-basic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def label_img(img):\n",
    "    # Images are formatted as: ADIDAS_1, NIKE_3 ...\n",
    "    word_label = img.split('_')[0]\n",
    "    if word_label == 'OFFWHITE': return [1,0] #one hot encoding\n",
    "    elif word_label == 'YEEZY': return [0,1] #one hot encoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_train_data():\n",
    "    train_data = []\n",
    "    for img in tqdm(os.listdir(TRAIN_DIR)):\n",
    "        \n",
    "        print(img)\n",
    "        label = label_img(img)\n",
    "        path = os.path.join(TRAIN_DIR, img)\n",
    "        if path == \"/Users/Lucas_Ying/Desktop/ATCS/Final Project_SneakerIdentifier/Sneaker-Identifier/data/TrainingData/.DS_Store\":\n",
    "            break\n",
    "        print(\"Loading image from path:\", path)  # Debugging output to check the path\n",
    "        img = cv2.resize(cv2.imread(path, cv2.IMREAD_GRAYSCALE), (IMG_SIZE, IMG_SIZE))  # Read image in grayscale\n",
    "        train_data.append([np.array(img), np.array(label)])\n",
    "    shuffle(train_data)\n",
    "    np.save('train_data.npy', train_data) #.npy extension = numpy file\n",
    "    return train_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def process_test_data():\n",
    "    test_data = []\n",
    "    for img in tqdm(os.listdir(TEST_DIR)):\n",
    "        path = os.path.join(TEST_DIR, img)\n",
    "        img_num = img.split('_')[1] #images are formatted 'OFFWHITE_2', 'YEEZY_56'..\n",
    "        read = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "        img = cv2.resize(read, (IMG_SIZE,IMG_SIZE))\n",
    "        \n",
    "        test_data.append([np.array(img), img_num])\n",
    "    shuffle(test_data)\n",
    "    np.save('test_data.npy', test_data)\n",
    "    return test_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".DS_Store\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_data = create_train_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tflearn\n",
    "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
    "from tflearn.layers.core import input_data, dropout, fully_connected\n",
    "from tflearn.layers.estimator import regression\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.reset_default_graph()\n",
    "\n",
    "convnet = input_data(shape=[None, IMG_SIZE, IMG_SIZE, 1], name = 'input')\n",
    "convnet = conv_2d(convnet, 32, 5, activation = 'relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "convnet = conv_2d(convnet, 64, 5, activation = 'relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "convnet = conv_2d(convnet, 32, 5, activation = 'relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "convnet = conv_2d(convnet, 64, 5, activation = 'relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "convnet = conv_2d(convnet, 32, 5, activation = 'relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "convnet = conv_2d(convnet, 64, 5, activation = 'relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "convnet = fully_connected(convnet, 1024, activation = 'relu')\n",
    "convnet = dropout(convnet, 0.8)\n",
    "convnet = fully_connected(convnet, 2, activation = 'softmax')\n",
    "convnet = regression(convnet, optimizer = 'adam', learning_rate = LR, loss = 'categorical_crossentropy', name = 'targets')\n",
    "model = tflearn.DNN(convnet, tensorboard_verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA SPLITTING\n",
    "# Data splitting is typically done 80% train and 20% test\n",
    "# of the 80% of our data in the train set\n",
    "# we set aside a small percentage as a validation set\n",
    "# this is used to do parameter tuning before evaluating\n",
    "# on our test set\n",
    "\n",
    "train = train_data[-90:] #Train Set\n",
    "test = train_data[:-90] #Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([i[0] for i in train]).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
    "Y = [i[1] for i in train]\n",
    "\n",
    "test_x = np.array([i[0] for i in test]).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
    "test_y = [i[1] for i in test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit({'input': X}, {'targets': Y}, n_epoch=100, validation_set=({'input': test_x}, {'targets': test_y}), snapshot_step=50, show_metric=True, run_id='OFFWHITE_YEEZY')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = process_test_data()\n",
    "fig = plt.figure()\n",
    "\n",
    "for num, data in enumerate(test_data[:10]):\n",
    "    img_num = data[1]\n",
    "    img_data = data[0]\n",
    "    \n",
    "    y = fig.add_subplot(3,4,num+1)\n",
    "    orig = img_data\n",
    "    data = img_data.reshape(IMG_SIZE, IMG_SIZE, 1)\n",
    "    model_out = model.predict([data])[0]\n",
    "    print(model_out)\n",
    "    if np.argmax(model_out) == 1:\n",
    "        str_label = 'YEEZY'\n",
    "    else:\n",
    "        str_label = 'OFFWHITE'\n",
    "    \n",
    "    y.imshow(orig, cmap = 'gray')\n",
    "    plt.title(str_label)\n",
    "    y.axes.get_xaxis().set_visible(False)\n",
    "    y.axes.get_yaxis().set_visible(False)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
